{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import zoom\n",
    "import numpy.linalg as npl\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "#import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist = list()\n",
    "# Find the working directory\n",
    "Wdir = %pwd\n",
    "# List the mhd files in folder \"data\" in the working directory\n",
    "for file in os.listdir(Wdir + '/data'):\n",
    "    if fnmatch.fnmatch(file, '*.mhd'):\n",
    "        datalist.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore variation of spacings and dimensions of different CTs\n",
    "Spacings = np.empty([len(datalist),3])\n",
    "Dims = np.empty([len(datalist),3])\n",
    "for nmbr in range(0,len(datalist)):\n",
    "    #print(nmbr)\n",
    "    path = Wdir + '\\\\data\\\\'\n",
    "    itkimg = sitk.ReadImage(path + datalist[nmbr]) # Reads the image using SimpleITK\n",
    "    CT_scan = sitk.GetArrayFromImage(itkimg) # First converts the image to a numpy array, then shuffles the dimensions to get the order z,y,x\n",
    "    spc = itkimg.GetSpacing() # Voxel size\n",
    "    Spacings[nmbr] = spc\n",
    "    dm = CT_scan.shape\n",
    "    Dims[nmbr] = dm\n",
    "    \n",
    "# np.save('Spacings.npy', Spacings)\n",
    "# np.save('Dims.npy', Dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spacings = np.load('Spacings.npy')\n",
    "Dims = np.load('Dims.npy')\n",
    "\n",
    "plt.hist(Spacings[:,0])\n",
    "plt.title('Distribution of Voxel Dimension 1')\n",
    "plt.figure()\n",
    "plt.hist(Spacings[:,1])\n",
    "plt.title('Distribution of Voxel Dimension 2')\n",
    "plt.figure()\n",
    "plt.hist(Spacings[:,2])\n",
    "plt.title('Distribution of Voxel Dimension 3')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(Dims[:,2])\n",
    "plt.title('Distribution of CT Dimension 1')\n",
    "plt.figure()\n",
    "plt.hist(Dims[:,1])\n",
    "plt.title('Distribution of CT Dimension 2')\n",
    "plt.figure()\n",
    "plt.hist(Dims[:,0])\n",
    "plt.title('Distribution of CT Dimension 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads mhd/raw image using SimpleITK & returns image numpy array, offset & spacing of the image, and the coordinates transformation matrix\n",
    "def readMhd(filename):\n",
    "\n",
    "    itkimg = sitk.ReadImage(filename)\n",
    "    CT_scan = sitk.GetArrayFromImage(itkimg)\n",
    "    Spacing = itkimg.GetSpacing() \n",
    "    Offset = itkimg.GetOrigin() # Reads world coordinates of origin\n",
    "    TransformMat = itkimg.GetDirection() # Reads transformation matrix\n",
    "    TransformMat = np.asarray([TransformMat[0:3],TransformMat[3:6],TransformMat[6:9]])\n",
    "    \n",
    "    return CT_scan,Spacing,Offset,TransformMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms real world to image coordinates for a point\n",
    "def Wrld2Img(real_pt,Offset,Spacing,TransformMat):\n",
    "    \n",
    "    img_pt = real_pt - Offset\n",
    "    for i in range(0,3):\n",
    "        TransformMat[:,i] = TransformMat[:,i]*Spacing[i]\n",
    "    Wrld2ImgMat = npl.inv(TransformMat) \n",
    "    img_pt = np.round(np.matmul(Wrld2ImgMat,img_pt))    \n",
    "    return img_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pads the image (if necessary) for the centroid to be in the middle\n",
    "def Padd(CT_scan, ctrd, PatchHalfSize):\n",
    "    \n",
    "    if np.any(ctrd<PatchHalfSize) or np.any(ctrd+PatchHalfSize>CT_scan.shape): # check if padding is necessary\n",
    "        ctrd = ctrd + max(PatchHalfSize)\n",
    "        CT_scan = np.pad(CT_scan,((max(PatchHalfSize),max(PatchHalfSize),)),mode='edge')\n",
    "        \n",
    "    return CT_scan,ctrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts a cube at the given centroid & resamples the scan\n",
    "def XtrctCube(CT_scan, ctrd, PatchHalfSize, PatchSize_v):\n",
    "    \n",
    "    Patch = CT_scan[ctrd[0]-PatchHalfSize[0]:ctrd[0]+PatchHalfSize[0], ctrd[1]-PatchHalfSize[1]:ctrd[1]+PatchHalfSize[1], ctrd[2]-PatchHalfSize[2]:ctrd[2]+PatchHalfSize[2]]\n",
    "    Patch = zoom(Patch,(PatchSize_v/Patch.shape[0],PatchSize_v/Patch.shape[1],PatchSize_v/Patch.shape[2]),order=2) #resample for cube_size\n",
    "    \n",
    "    return Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts a cube of the specified size around the given coordinates ctrd\n",
    "def GetPatch(CT_scan,ctrd,PatchSize_v,PatchSize_mm,Spacing):\n",
    "    \n",
    "    ctrd = np.asarray(list(reversed(ctrd)), dtype=np.int)\n",
    "    Spacing = np.asarray(list(reversed(Spacing)))\n",
    "    \n",
    "    PatchHalfSize = np.asarray((PatchSize_mm/Spacing)/2,dtype=np.int) # Half of cube-size in voxels\n",
    "    [CT_scan,ctrd] = Padd(CT_scan, ctrd, PatchHalfSize)\n",
    "    Patch = XtrctCube(CT_scan, ctrd, PatchHalfSize, PatchSize_v)\n",
    "           \n",
    "    return Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the destination of saving extracted cube of scan/mask according to radiologist number: R1, R2, R3, R4, R5 existing folder names\n",
    "def Path(rad):\n",
    "    switcher={\n",
    "            1: 'R1',\n",
    "            2: 'R2',\n",
    "            3: 'R3',\n",
    "#             4: 'R4',\n",
    "#             5: 'R5'\n",
    "            }\n",
    "    return switcher.get(rad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly rotates an image by a random angle\n",
    "def RandRotate (Scan, maxAngle):\n",
    "    angle = np.random.uniform(-maxAngle, maxAngle)\n",
    "    scn1 = rotate(Scan, angle, mode='nearest', axes=(0,1), reshape=False) # Rotate along z-axis\n",
    "\n",
    "    angle = np.random.uniform(-maxAngle, maxAngle)\n",
    "    scn2 = rotate(scn1, angle, mode='nearest', axes=(0, 2), reshape=False) # Rotate along y-axis\n",
    "\n",
    "    angle = np.random.uniform(-maxAngle, maxAngle)\n",
    "    RotScan = rotate(scn2, angle, mode='nearest', axes=(1, 2), reshape=False) # Rotate along x-axis\n",
    "        \n",
    "    return RotScan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augments the data by doing flip & transpose\n",
    "def Augment(Scan):\n",
    "    Aug1 = np.flip(Scan, axis=0)\n",
    "    Aug2 = np.flip(Scan, axis=1)\n",
    "    Aug3 = np.flip(Scan, axis=2)\n",
    "    Aug4 = np.transpose(Scan, (0, 2, 1))\n",
    "    \n",
    "    return Aug1,Aug2,Aug3,Aug4\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('trainNodules.csv') # Read nodules csv\n",
    "LNDbIDs = df.LNDbID\n",
    "RadIDs = df.RadID\n",
    "FindingIDs = df.FindingID\n",
    "\n",
    "for i in range(0,len(LNDbIDs)):\n",
    "    #time.sleep(1)\n",
    "    #print(i)\n",
    "    \n",
    "    lnd = LNDbIDs[i] # i-th row of trainNodules.csv\n",
    "    rad = RadIDs[i]\n",
    "    finding = FindingIDs[i]\n",
    "\n",
    "    [CT_scan,Spacing,Offset,TransformMat] =  readMhd('data/LNDb-{:04}.mhd'.format(lnd))\n",
    "    [Mask,Spacing,Offset,TransformMat] =  readMhd('masks/LNDb-{:04}_rad{}.mhd'.format(lnd,rad))\n",
    "    \n",
    "    # Read the centroid of the nodule\n",
    "    a = LNDbIDs == lnd\n",
    "    b = RadIDs == rad\n",
    "    c = FindingIDs == finding\n",
    "    ctrd = np.array([float(df.x[a&b&c]), float(df.y[a&b&c]), float(df.z[a&b&c])])\n",
    "    \n",
    "    ctrd = Wrld2Img(ctrd,Offset,Spacing,TransformMat) # Convert world coordinates to image coordinates\n",
    "    \n",
    "    # Display nodule scan/mask slice\n",
    "#     fig, axs = plt.subplots(1,2)\n",
    "#     axs[0].imshow(CT_scan[int(ctrd[2])])\n",
    "#     axs[1].imshow(Mask[int(ctrd[2])])\n",
    "#     plt.show() \n",
    "    \n",
    "    # Extract cube around nodule\n",
    "    PatchSize_v = 80 # We should submit a 80x80x80 cube with voxelsize 0.6375mm centered on the nodule centroid with the predicted segmentation for each nodule.\n",
    "    PatchSize_mm = 51 # 80*0.6375 = 51, about 70% larger than the diameter of the largest nodule\n",
    "    ScanPatch = GetPatch(CT_scan,ctrd,PatchSize_v,PatchSize_mm,Spacing)\n",
    "    Mask[Mask>0] = 1\n",
    "    Mask[Mask!=finding] = 0\n",
    "    MaskPatch = GetPatch(Mask,ctrd,PatchSize_v,PatchSize_mm,Spacing)\n",
    "        \n",
    "    PATH = Path(rad)\n",
    "    np.save(os.path.join(PATH , 'LNDb{:04}-R{:01}-F{:01}.npy'.format(lnd, rad, finding)), ScanPatch)\n",
    "    np.save(os.path.join(PATH , 'Mask_LNDb{:04}-R{:01}-F{:01}.npy'.format(lnd, rad, finding)), MaskPatch)\n",
    "\n",
    "    \n",
    "    # Display mid slices from resampled scan/mask\n",
    "#     fig, axs = plt.subplots(2,3)\n",
    "#     axs[0,0].imshow(ScanPatch[int(ScanPatch.shape[0]/2),:,:])\n",
    "#     axs[1,0].imshow(MaskPatch[int(MaskPatch.shape[0]/2),:,:])\n",
    "#     axs[0,1].imshow(ScanPatch[:,int(ScanPatch.shape[1]/2),:])\n",
    "#     axs[1,1].imshow(MaskPatch[:,int(MaskPatch.shape[1]/2),:])\n",
    "#     axs[0,2].imshow(ScanPatch[:,:,int(ScanPatch.shape[2]/2)])\n",
    "#     axs[1,2].imshow(MaskPatch[:,:,int(MaskPatch.shape[2]/2)])    \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R1 Folder Augmentation\n",
    "datalist = list()\n",
    "Wdir = %pwd\n",
    "for file in os.listdir(Wdir + '/Data2_80/R1'):\n",
    "    if fnmatch.fnmatch(file, '*.npy'):\n",
    "        datalist.append(file)\n",
    "        \n",
    "for nmbr in range(0,int(len(datalist)/2)):\n",
    "#     print(nmbr)\n",
    "    Scan = np.load(os.path.join('Data2_80', 'R1', datalist[nmbr]))\n",
    "    Mask = np.load(os.path.join('Data2_80', 'R1', datalist[nmbr+int(len(datalist)/2)]))\n",
    "    [SAug1,SAug2,SAug3,SAug4] = Augment(Scan)\n",
    "    [MAug1,MAug2,MAug3,MAug4] = Augment(Mask)\n",
    "    \n",
    "    np.save(os.path.join('Data2_80/R1/R1Aug', 'Aug1_' + datalist[nmbr]), SAug1)\n",
    "    np.save(os.path.join('Data2_80/R1/R1Aug', 'Aug2_' + datalist[nmbr]), SAug2)\n",
    "    np.save(os.path.join('Data2_80/R1/R1Aug', 'Aug3_' + datalist[nmbr]), SAug3)\n",
    "    np.save(os.path.join('Data2_80/R1/R1Aug', 'Aug4_' + datalist[nmbr]), SAug4)\n",
    "    np.save(os.path.join('Data2_80/R1/R1Aug', 'Aug1_' + datalist[nmbr+int(len(datalist)/2)]), MAug1)\n",
    "    np.save(os.path.join('Data2_80/R1/R1Aug', 'Aug2_' + datalist[nmbr+int(len(datalist)/2)]), MAug2)\n",
    "    np.save(os.path.join('Data2_80/R1/R1Aug', 'Aug3_' + datalist[nmbr+int(len(datalist)/2)]), MAug3)\n",
    "    np.save(os.path.join('Data2_80/R1/R1Aug', 'Aug4_' + datalist[nmbr+int(len(datalist)/2)]), MAug4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 Folder Augmentation\n",
    "datalist = list()\n",
    "Wdir = %pwd\n",
    "for file in os.listdir(Wdir + '/Data2_80/R2'):\n",
    "    if fnmatch.fnmatch(file, '*.npy'):\n",
    "        datalist.append(file)\n",
    "        \n",
    "for nmbr in range(0,int(len(datalist)/2)):\n",
    "#     print(nmbr)\n",
    "    Scan = np.load(os.path.join('Data2_80', 'R2', datalist[nmbr]))\n",
    "    Mask = np.load(os.path.join('Data2_80', 'R2', datalist[nmbr+int(len(datalist)/2)]))\n",
    "    [SAug1,SAug2,SAug3,SAug4] = Augment(Scan)\n",
    "    [MAug1,MAug2,MAug3,MAug4] = Augment(Mask)\n",
    "    \n",
    "    np.save(os.path.join('Data2_80/R2/R2Aug', 'Aug1_' + datalist[nmbr]), SAug1)\n",
    "    np.save(os.path.join('Data2_80/R2/R2Aug', 'Aug2_' + datalist[nmbr]), SAug2)\n",
    "    np.save(os.path.join('Data2_80/R2/R2Aug', 'Aug3_' + datalist[nmbr]), SAug3)\n",
    "    np.save(os.path.join('Data2_80/R2/R2Aug', 'Aug4_' + datalist[nmbr]), SAug4)\n",
    "    np.save(os.path.join('Data2_80/R2/R2Aug', 'Aug1_' + datalist[nmbr+int(len(datalist)/2)]), MAug1)\n",
    "    np.save(os.path.join('Data2_80/R2/R2Aug', 'Aug2_' + datalist[nmbr+int(len(datalist)/2)]), MAug2)\n",
    "    np.save(os.path.join('Data2_80/R2/R2Aug', 'Aug3_' + datalist[nmbr+int(len(datalist)/2)]), MAug3)\n",
    "    np.save(os.path.join('Data2_80/R2/R2Aug', 'Aug4_' + datalist[nmbr+int(len(datalist)/2)]), MAug4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R3 Folder Augmentation\n",
    "datalist = list()\n",
    "Wdir = %pwd\n",
    "for file in os.listdir(Wdir + '/Data2_80/R3'):\n",
    "    if fnmatch.fnmatch(file, '*.npy'):\n",
    "        datalist.append(file)\n",
    "        \n",
    "for nmbr in range(0,int(len(datalist)/2)):\n",
    "#     print(nmbr)\n",
    "    Scan = np.load(os.path.join('Data2_80', 'R3', datalist[nmbr]))\n",
    "    Mask = np.load(os.path.join('Data2_80', 'R3', datalist[nmbr+int(len(datalist)/2)]))\n",
    "    [SAug1,SAug2,SAug3,SAug4] = Augment(Scan)\n",
    "    [MAug1,MAug2,MAug3,MAug4] = Augment(Mask)\n",
    "    \n",
    "    np.save(os.path.join('Data2_80/R3/R3Aug', 'Aug1_'+ datalist[nmbr]), SAug1)\n",
    "    np.save(os.path.join('Data2_80/R3/R3Aug', 'Aug2_' + datalist[nmbr]), SAug2)\n",
    "    np.save(os.path.join('Data2_80/R3/R3Aug', 'Aug3_' + datalist[nmbr]), SAug3)\n",
    "    np.save(os.path.join('Data2_80/R3/R3Aug', 'Aug4_' + datalist[nmbr]), SAug4)\n",
    "    np.save(os.path.join('Data2_80/R3/R3Aug', 'Aug1_' + datalist[nmbr+int(len(datalist)/2)]), MAug1)\n",
    "    np.save(os.path.join('Data2_80/R3/R3Aug', 'Aug2_' + datalist[nmbr+int(len(datalist)/2)]), MAug2)\n",
    "    np.save(os.path.join('Data2_80/R3/R3Aug', 'Aug3_' + datalist[nmbr+int(len(datalist)/2)]), MAug3)\n",
    "    np.save(os.path.join('Data2_80/R3/R3Aug', 'Aug4_' + datalist[nmbr+int(len(datalist)/2)]), MAug4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
